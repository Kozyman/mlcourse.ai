{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating decision tree criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):    \n",
    "    y = np.array(y)\n",
    "    num_items = len(y)\n",
    "    classes = np.unique(y)\n",
    "    p = {}\n",
    "    for c in classes:\n",
    "        if num_items == 0:\n",
    "            p[c] = 0\n",
    "        else:\n",
    "            p[c] = sum(y==c)/num_items\n",
    "    probs = np.array([val for val in p.values()])\n",
    "    log_probs = np.log2(probs)\n",
    "    F = -np.dot(probs,log_probs.T)\n",
    "    return F\n",
    "\n",
    "def gini(y):\n",
    "    y = np.array(y)\n",
    "    num_items = len(y)\n",
    "    classes = np.unique(y)\n",
    "    p = {}\n",
    "    for c in classes:\n",
    "        if num_items == 0:\n",
    "            p[c] = 0\n",
    "        else:\n",
    "            p[c] = sum(y==c)/num_items\n",
    "    probs = np.array([val for val in p.values()])\n",
    "    F = 1-np.sum(np.square(probs))\n",
    "    return F\n",
    "\n",
    "impurity_dict = {'entropy':entropy, 'gini':gini}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating elements of the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, feature_idx=0, threshold=0, labels=None, left=None, right=None):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.labels = labels\n",
    "        self.left = left\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2, \n",
    "                 criterion='gini', debug=False):\n",
    "        self.criterion = criterion\n",
    "        self.min_samples = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.debug = debug\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        best_gain = 0\n",
    "        current_impurity = impurity_dict[self.criterion](y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        return print(current_impurity)\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_splits(rows, question):\n",
    "    true_rows, false_rows = [], []\n",
    "    Trow_ind = []\n",
    "    Frow_ind = []\n",
    "    ind = 0\n",
    "    for row in rows:\n",
    "        if question.row_match(row):\n",
    "            true_rows.append(row)\n",
    "            Trow_ind.append(ind)\n",
    "            ind += 1\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "            Frow_ind.append(ind)\n",
    "            ind += 1\n",
    "    return true_rows, false_rows, Trow_ind, Frow_ind\n",
    "\n",
    "def get_split_costs(rows):\n",
    "    num_rows, num_columns = rows.shape\n",
    "    for row in rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(test_value):\n",
    "    return isinstance(test_value, (float, int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    def __init__(self, column_num, value):\n",
    "        self.column_num = column_num\n",
    "        self.value = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        if is_number(self.value):\n",
    "            equation = '>='\n",
    "        else:\n",
    "            equation = '=='\n",
    "        return 'Is Column{} {} {}?'.format(self.column_num, equation, self.value)\n",
    "        \n",
    "    def row_match(self, test_row):\n",
    "        val = test_row[self.column_num]\n",
    "        if is_number(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trialData = [\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 3, 'Apple'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "]  ## this is a list\n",
    "\n",
    "trialData = np.array(trialData) ## convert to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trialData))\n",
    "trialX = trialData[:,:2]\n",
    "trialy = trialData[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5219280948873621"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(trialy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "r, c = trialData.shape\n",
    "print(r+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Column0 == Green?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Question(0, 'Green'))\n",
    "q1.row_match(trialData[0])\n",
    "# list(trialData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
